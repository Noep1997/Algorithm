## This file provides starter code for extracting features from the xml files and
## for doing some learning.
##
## The basic set-up:
## ----------------
## main() will run code to extract features, learn, and make predictions.
##
## extract_feats() is called by main(), and it will iterate through the
## train/test directories and parse each xml file into an xml.etree.ElementTree,
## which is a standard python object used to represent an xml file in memory.
## (More information about xml.etree.ElementTree objects can be found here:
## http://docs.python.org/2/library/xml.etree.elementtree.html
## and here: http://eli.thegreenplace.net/2012/03/15/processing-xml-in-python-with-elementtree/)
## It will then use a series of "feature-functions" that you will write/modify
## in order to extract dictionaries of features from each ElementTree object.
## Finally, it will produce an N x D sparse design matrix containing the union
## of the features contained in the dictionaries produced by your "feature-functions."
## This matrix can then be plugged into your learning algorithm.
##
## The learning and prediction parts of main() are largely left to you, though
## it does contain code that randomly picks class-specific weights and predicts
## the class with the weights that give the highest score. If your prediction
## algorithm involves class-specific weights, you should, of course, learn
## these class-specific weights in a more intelligent way.
##
## Feature-functions:
## --------------------
## "feature-functions" are functions that take an ElementTree object representing
## an xml file (which contains, among other things, the sequence of system calls a
## piece of potential malware has made), and returns a dictionary mapping feature names to
## their respective numeric values.
## For instance, a simple feature-function might map a system call history to the
## dictionary {'first_call-load_image': 1}. This is a boolean feature indicating
## whether the first system call made by the executable was 'load_image'.
## Real-valued or count-based features can of course also be defined in this way.
## Because this feature-function will be run over ElementTree objects for each
## software execution history instance, we will have the (different)
## feature values of this feature for each history, and these values will make up
## one of the columns in our final design matrix.
## Of course, multiple features can be defined within a single dictionary, and in
## the end all the dictionaries returned by feature functions (for a particular
## training example) will be unioned, so we can collect all the feature values
## associated with that particular instance.
##
## Two example feature-functions, first_last_system_call_feats() and
## system_call_count_feats(), are defined below.
## The first of these functions indicates what the first and last system-calls
## made by an executable are, and the second records the total number of system
## calls made by an executable.
##
## What you need to do:
## --------------------
## 1. Write new feature-functions (or modify the example feature-functions) to
## extract useful features for this prediction task.
## 2. Implement an algorithm to learn from the design matrix produced, and to
## make predictions on unseen data. Naive code for these two steps is provided
## below, and marked by TODOs.
##
## Computational Caveat
## --------------------
## Because the biggest of any of the xml files is only around 35MB, the code below
## will parse an entire xml file and store it in memory, compute features, and
## then get rid of it before parsing the next one. Storing the biggest of the files
## in memory should require at most 200MB or so, which should be no problem for
## reasonably modern laptops. If this is too much, however, you can lower the
## memory requirement by using ElementTree.iterparse(), which does parsing in
## a streaming way. See http://eli.thegreenplace.net/2012/03/15/processing-xml-in-python-with-elementtree/
## for an example.
import os
from collections import Counter
try:
    import xml.etree.cElementTree as ET
except ImportError:
    import xml.etree.ElementTree as ET
import numpy as np
from scipy import sparse
import util
##################### CODE WE ADDED ############################################
# these are the imports for the models we will train
from sklearn import svm # SVM Classification Model
from sklearn.naive_bayes import MultinomialNB # Multinomial Naive Bayes
from sklearn.ensemble import RandomForestClassifier # Random Forest
from sklearn.ensemble import GradientBoostingClassifier # Gradient Boosted Random Forest
from sklearn.ensemble import AdaBoostClassifier # AdaBoost Classifier
import nltk # Nltk for Bigrams
from nltk.util import ngrams # Nltk for Trigrams & More
################################################################################
def extract_feats(ffs, direc="train", global_feat_dict=None):
    """
    arguments:
      ffs are a list of feature-functions.
      direc is a directory containing xml files (expected to be train or test).
      global_feat_dict is a dictionary mapping feature_names to column-numbers; it
      should only be provided when extracting features from test data, so that
      the columns of the test matrix align correctly.

    returns:
      a sparse design matrix, a dict mapping features to column-numbers,
      a vector of target classes, and a list of system-call-history ids in order
      of their rows in the design matrix.

      Note: the vector of target classes returned will contain the true indices of the
      target classes on the training data, but will contain only -1's on the test
      data
    """
    fds = [] # list of feature dicts
    classes = []
    ids = []
    for datafile in os.listdir(direc):
        # extract id and true class (if available) from filename
        id_str,clazz = datafile.split('.')[:2]
        ids.append(id_str)
        # add target class if this is training data
        try:
            classes.append(util.malware_classes.index(clazz))
        except ValueError:
            # we should only fail to find the label in our list of malware classes
            # if this is test data, which always has an "X" label
            assert clazz == "X"
            classes.append(-1)
        rowfd = {}
        # parse file as an xml document
        tree = ET.parse(os.path.join(direc,datafile))
        # accumulate features
        [rowfd.update(ff(tree)) for ff in ffs]
        fds.append(rowfd)
    X,feat_dict = make_design_mat(fds,global_feat_dict)
    return X, feat_dict, np.array(classes), ids

def make_design_mat(fds, global_feat_dict=None):
    """
    arguments:
      fds is a list of feature dicts (one for each row).
      global_feat_dict is a dictionary mapping feature_names to column-numbers; it
      should only be provided when extracting features from test data, so that
      the columns of the test matrix align correctly.
    returns:
        a sparse NxD design matrix, where N == len(fds) and D is the number of
        the union of features defined in any of the fds
    """
    if global_feat_dict is None:
        all_feats = set()
        [all_feats.update(fd.keys()) for fd in fds]
        feat_dict = dict([(feat, i) for i, feat in enumerate(sorted(all_feats))])
    else:
        feat_dict = global_feat_dict
    cols = []
    rows = []
    data = []
    for i in range(len(fds)):
        temp_cols = []
        temp_data = []
        for feat,val in fds[i].items():
            try:
                # update temp_cols iff update temp_data
                temp_cols.append(feat_dict[feat])
                temp_data.append(val)
            except KeyError as ex:
                if global_feat_dict is not None:
                    pass  # new feature in test data; nbd
                else:
                    raise ex
        # all fd's features in the same row
        k = len(temp_cols)
        cols.extend(temp_cols)
        data.extend(temp_data)
        rows.extend([i]*k)

    assert len(cols) == len(rows) and len(rows) == len(data)

    X = sparse.csr_matrix((np.array(data),
                   (np.array(rows), np.array(cols))),
                   shape=(len(fds), len(feat_dict)))
    return X, feat_dict
##################### CODE WE ADDED ############################################
## Categorization Accuracy as defined in the practical pdf
## This function does our accuracy metric
def categ_accuracy(model, X_test, true_y):
    predictions = model.predict(X_test)
    correct_class = 0
    for i in range(len(predictions)):
        if predictions[i] == true_y[i]:
            correct_class += 1
    return correct_class / len(predictions)
################################################################################
## Here are two example feature-functions. They each take an xml.etree.ElementTree object,
# (i.e., the result of parsing an xml file) and returns a dictionary mapping
# feature-names to numeric values.
## TODO: modify these functions, and/or add new ones.
def first_last_system_call_feats(tree):
    """
    arguments:
      tree is an xml.etree.ElementTree object
    returns:
      a dictionary mapping 'first_call-x' to 1 if x was the first system call
      made, and 'last_call-y' to 1 if y was the last system call made.
      (in other words, it returns a dictionary indicating what the first and
      last system calls made by an executable were.)
    """
    c = Counter()
    in_all_section = False
    first = True # is this the first system call
    last_call = None # keep track of last call we've seen
    for el in tree.iter():
        # ignore everything outside the "all_section" element
        if el.tag == "all_section" and not in_all_section:
            in_all_section = True
        elif el.tag == "all_section" and in_all_section:
            in_all_section = False
        elif in_all_section:
            if first:
                c["first_call-"+el.tag] = 1
                first = False
            last_call = el.tag  # update last call seen
    # finally, mark last call seen
    c["last_call-"+last_call] = 1
    return c

def system_call_count_feats(tree):
    """
    arguments:
      tree is an xml.etree.ElementTree object
    returns:
      a dictionary mapping 'num_system_calls' to the number of system_calls
      made by an executable (summed over all processes)
    """
    c = Counter()
    in_all_section = False
    for el in tree.iter():
        # ignore everything outside the "all_section" element
        if el.tag == "all_section" and not in_all_section:
            in_all_section = True
        elif el.tag == "all_section" and in_all_section:
            in_all_section = False
        elif in_all_section:
            c['num_system_calls'] += 1
    return c
##################### CODE WE ADDED ############################################
# We now want to do features engineering. Since we know little about XML files,
# we printed the el.tag of the XML tree structure and decided to use the most
# frequent tags as additional features to consider in our classification. This
# gave rise to the following features, which we count the number of occurence

# we printed el.tag and there were a lot of load-dll, so we want to take their
# count and pass it in as a parameter for our models
def system_load_dll_feats(tree):
    """
    arguments:
      tree is an xml.etree.ElementTree object
    returns:
      a dictionary mapping 'load_dll' to the number of load_dll made by an
      executable (summed over all processes)
    """
    c = Counter()
    in_all_section = False
    for el in tree.iter():
        # ignore everything outside the "all_section" element
        if el.tag == "all_section" and not in_all_section:
            in_all_section = True
        elif el.tag == "all_section" and in_all_section:
            in_all_section = False
        elif in_all_section:
            if el.tag == 'load_dll':
                c['load_dll'] += 1
    return c

# we printed el.tag and there were a lot of open_key, so we want to take their
# count and pass it in as a parameter for our models
def system_open_key_feats(tree):
    """
    arguments:
      tree is an xml.etree.ElementTree object
    returns:
      a dictionary mapping 'open_key' to the number of open_key made by an
      executable (summed over all processes)
    """
    c = Counter()
    in_all_section = False
    for el in tree.iter():
        # ignore everything outside the "all_section" element
        if el.tag == "all_section" and not in_all_section:
            in_all_section = True
        elif el.tag == "all_section" and in_all_section:
            in_all_section = False
        elif in_all_section:
            if el.tag == 'open_key':
                c['open_key'] += 1
    return c

# we printed el.tag and there were a lot of vm_protect, so we want to take their
# count and pass it in as a parameter for our models
def system_vm_protect_feats(tree):
    """
    arguments:
      tree is an xml.etree.ElementTree object
    returns:
      a dictionary mapping 'vm_protect' to the number of vm_protect made by an
      executable (summed over all processes)
    """
    c = Counter()
    in_all_section = False
    for el in tree.iter():
        # ignore everything outside the "all_section" element
        if el.tag == "all_section" and not in_all_section:
            in_all_section = True
        elif el.tag == "all_section" and in_all_section:
            in_all_section = False
        elif in_all_section:
            if el.tag == 'vm_protect':
                c['vm_protect'] += 1
    return c

# we printed el.tag and there were a lot of dump_line, so we want to take their
# count and pass it in as a parameter for our models
def system_dump_line_feats(tree):
    """
    arguments:
      tree is an xml.etree.ElementTree object
    returns:
      a dictionary mapping 'dump_line' to the number of dump_line made by an
      executable (summed over all processes)
    """
    c = Counter()
    in_all_section = False
    for el in tree.iter():
        # ignore everything outside the "all_section" element
        if el.tag == "all_section" and not in_all_section:
            in_all_section = True
        elif el.tag == "all_section" and in_all_section:
            in_all_section = False
        elif in_all_section:
            if el.tag == 'dump_line':
                c['dump_line'] += 1
    return c

# we printed el.tag and there were a lot of delete file, so we want to take their
# count and pass it in as a parameter for our models
def system_delete_file_feats(tree):
    """
    arguments:
      tree is an xml.etree.ElementTree object
    returns:
      a dictionary mapping 'delete_file' to the number of delete_file made by an
      executable (summed over all processes)
    """
    c = Counter()
    in_all_section = False
    for el in tree.iter():
        # ignore everything outside the "all_section" element
        if el.tag == "all_section" and not in_all_section:
            in_all_section = True
        elif el.tag == "all_section" and in_all_section:
            in_all_section = False
        elif in_all_section:
            if el.tag == 'delete_file':
                c['delete_file'] += 1
    return c

# we printed el.tag and there were a lot of remove_directory, so we want to take their
# count and pass it in as a parameter for our models
def system_remove_directory_feats(tree):
    """
    arguments:
      tree is an xml.etree.ElementTree object
    returns:
      a dictionary mapping 'remove_directory' to the number of remove_directory
      made by an executable (summed over all processes)
    """
    c = Counter()
    in_all_section = False
    for el in tree.iter():
        # ignore everything outside the "all_section" element
        if el.tag == "all_section" and not in_all_section:
            in_all_section = True
        elif el.tag == "all_section" and in_all_section:
            in_all_section = False
        elif in_all_section:
            if el.tag == 'remove_directory':
                c['remove_directory'] += 1
    return c

# we printed el.tag and there were a lot of create_directory, so we want to take their
# count and pass it in as a parameter for our models
def system_create_directory_feats(tree):
    """
    arguments:
      tree is an xml.etree.ElementTree object
    returns:
      a dictionary mapping 'create_directory' to the number of create_directory
      made by an executable (summed over all processes)
    """
    c = Counter()
    in_all_section = False
    for el in tree.iter():
        # ignore everything outside the "all_section" element
        if el.tag == "all_section" and not in_all_section:
            in_all_section = True
        elif el.tag == "all_section" and in_all_section:
            in_all_section = False
        elif in_all_section:
            if el.tag == 'create_directory':
                c['create_directory'] += 1
    return c

# At first, adding new features greatly increased our classfication accuracy, but
# we realized that adding the last few features had very minimal difference. It
# seems like this strategy is exhausted and we need to take another approach to
# improving our accuracy score.

# While researching online, we realized that using a pairing of executable calls
# in the XML document could be a good way to detect malware, as some calls are
# often paired together for some malware attacks. This was also in accordance
# with the fact that the Bigrams baseline on Kaggle was relatively high.
# These are the two sources which led to this conclusion:
# https://www.hindawi.com/journals/jcnc/2016/8069672/
# http://www.mlsec.org/malheur/docs/malheur-jcs.pdf
# We therefore try our model on bigrams, trigrams and quadrigramas (after which
# any other attempts seem somewhat arbitrary and unnecessary)

# Features engineering: bigrams of system calls, we count the number of bigrams
# of each type. This should return us a quite large features matrix eventually
def system_bigrams_feats(tree):
    """
    arguments:
      tree is an xml.etree.ElementTree object
    returns:
      a dictionary mapping bigrams to the number of this specific bigram
      made by an executable (summed over all processes)
    """
    c = Counter()
    in_all_section = False
    tree_elems = [] # to store the tree system calls elements
    for el in tree.iter():
        # ignore everything outside the "all_section" element
        if el.tag == "all_section" and not in_all_section:
            in_all_section = True
        elif el.tag == "all_section" and in_all_section:
            in_all_section = False
        elif in_all_section:
            tree_elems.append(str(el.tag))
    # now that we have the list of calls, get the bigrams
    bigrams = nltk.bigrams(tree_elems)
    # now that we have the bigrams, we can count them
    for bigram in bigrams:
        c[str(bigram)] += 1
    return c

# Features engineering: trigrams of system calls, we count the number of trigrams
# of each type. This should return us a quite large features matrix eventually
def system_trigrams_feats(tree):
    """
    arguments:
      tree is an xml.etree.ElementTree object
    returns:
      a dictionary mapping trigrams to the number of this specific trigram
      made by an executable (summed over all processes)
    """
    c = Counter()
    in_all_section = False
    tree_elems = [] # to store the elements and then use this for getting bigrams
    for el in tree.iter():
        # ignore everything outside the "all_section" element
        if el.tag == "all_section" and not in_all_section:
            in_all_section = True
        elif el.tag == "all_section" and in_all_section:
            in_all_section = False
        elif in_all_section:
            tree_elems.append(str(el.tag))
    # now that we have the list, get the trigrams
    trigrams = ngrams(tree_elems, 3)
    # now that we have the trigrams, we can count them
    for trigram in trigrams:
        c[str(trigram)] += 1
    return c

# Features engineering: quadrigrams of system calls, we count the number of quadrigrams
# of each type. This should return us a quite large features matrix eventually
def system_quadrigrams_feats(tree):
    """
    arguments:
      tree is an xml.etree.ElementTree object
    returns:
      a dictionary mapping quadrigrams to the number of this specific quadrigram
      made by an executable (summed over all processes)
    """
    c = Counter()
    in_all_section = False
    tree_elems = [] # to store the elements and then use this for getting bigrams
    for el in tree.iter():
        # ignore everything outside the "all_section" element
        if el.tag == "all_section" and not in_all_section:
            in_all_section = True
        elif el.tag == "all_section" and in_all_section:
            in_all_section = False
        elif in_all_section:
            tree_elems.append(str(el.tag))
    # now that we have the list, get the bigrams
    quadrigrams = ngrams(tree_elems, 4)
    # now that we have the bigrams, we can count them
    for quadrigram in quadrigrams:
        c[str(quadrigram)] += 1
    return c
################################################################################
##################### CODE WE ADDED ############################################
## The following function does the feature extraction, learning, and prediction
# We modified it to train our multiple models and perform optimization
def main():
    train_dir = "train"
    test_dir = "test"
    outputfile = "sample_predictions.csv"  # feel free to change this or take it as an argument
    # DONE put the names of the feature functions you've defined above in this list
    # we added all of our features engineering, and we also tried multiple pairing
    # of system calls, bigrams, trigrams and quadrigrams
    # We ran each of these separately. The validation accuracy is reporte in
    # the latex table.

    # ffs without any grams, only features engineering
#    ffs = [first_last_system_call_feats, system_call_count_feats, system_load_dll_feats,
#            system_open_key_feats, system_vm_protect_feats, system_dump_line_feats,
#            system_delete_file_feats, system_remove_directory_feats, system_create_directory_feats]
    # bigram ffs
    ffs = [first_last_system_call_feats, system_call_count_feats, system_load_dll_feats,
            system_open_key_feats, system_vm_protect_feats, system_dump_line_feats,
            system_delete_file_feats, system_remove_directory_feats, system_create_directory_feats,
            system_bigrams_feats]
    # trigrams ffs
#    ffs = [first_last_system_call_feats, system_call_count_feats, system_load_dll_feats,
#            system_open_key_feats, system_vm_protect_feats, system_dump_line_feats,
#            system_delete_file_feats, system_remove_directory_feats, system_create_directory_feats,
#            system_trigrams_feats]
    # quadrigrams ffs
#    ffs = [first_last_system_call_feats, system_call_count_feats, system_load_dll_feats,
#            system_open_key_feats, system_vm_protect_feats, system_dump_line_feats,
#            system_delete_file_feats, system_remove_directory_feats, system_create_directory_feats,
#            system_quadrigrams_feats]

    # extract features
    print("extracting training features...")
    X_train,global_feat_dict,t_train,train_ids = extract_feats(ffs, train_dir)
    print("done extracting training features")
    print()

    # split x_Train into a train (75%) and validation set (25%)
    a1, a2, a3, a4 = np.split(X_train.todense()[:][:3080], 4)
    X_train_train = sparse.csr_matrix(np.vstack((a1, a2, a3)))
    X_train_valid = sparse.csr_matrix(a4)
    # split t_Train into a train (75%) and validation set (25%)
    a1, a2, a3, a4 = np.split(t_train[:3080], 4)
    t_train_train = np.concatenate((a1, a2, a3))
    t_train_valid = a4
    # As we can see, our validation technique is a bit simplistic. We are only
    # taking the last 25% chunk of the data, and we know the data is acquired
    # over a few days so we are validating on the later days. This gives us a
    # somewhat skewed validation set. That being said, we decide to stick with
    # it because what really matters in this validation scheme is the overall
    # hierarchy of which models do better, because we then re-train the best
    # model on the full training set to make our predictions to Kaggle.

    # DONE train here, and learn your classification parameters
    # we train naive bayes, svm, random forest and gradient boosted trees on
    # all three cases, bigrams, trigrams and quadrigrams
    print("learning...")
    # We first start with a multinomial naive bayes classifier, since this is
    # something we learned with the generative models, and it is a linear
    # model and thus relatively simple
    # 1nd - Multinomial Naive Bayes Classifier
    model_mnb = MultinomialNB()
    model_mnb.fit(X_train_train, t_train_train)
    x1 = categ_accuracy(model_mnb, X_train_valid, t_train_valid)
    print("MNB Classifier Accuracy: " + str(x1))
    # the result are not great, so we try a more complex linar model

    # next, we wanted to try an SVM sinc we started learning about SVM and it
    # is a slightly more complex and generalizable linear model
    # 2st - SVM Classifier
    model_svm = svm.SVC() # SVM Classifier
    model_svm.fit(X_train_train, t_train_train)
    x0 = categ_accuracy(model_svm, X_train_valid, t_train_valid)
    print("SVM Classifier Accuracy: " + str(x0))
    # the results are much better, but can still probably be better. We turn to
    # ensemble methods

    # next, we wanted to try a random forest classifier as an easier-to-train
    # non-linear model that worked really well on last practical
    # 3rd - Random Forest Classifier
    model_rf = RandomForestClassifier()
    model_rf.fit(X_train_train, t_train_train)
    x2 = categ_accuracy(model_rf, X_train_valid, t_train_valid)
    print("RF  Classifier Accuracy: " + str(x2))
    # this is quite good! We nonetheless try one last model

    # finally, we try gradient boosting trees as a supposedly better random forest
    # 4th - Gradient Boosting Classifier
    model_gb = GradientBoostingClassifier()
    model_gb.fit(X_train_train, t_train_train)
    x3 = categ_accuracy(model_gb, X_train_valid, t_train_valid)
    print("GB  Classifier Accuracy: " + str(x3))
    # does about the same as random forest, but not really better. let's see
    # what happens after doing grid search to optimize parameters.

    # The best appears to be a random forest, so we will use grid search
    # to improve the parameters
    # we save the best parameters here
    best_model_parameters = None
    # this is about the score from our random parameters, it will be our benchmark
    # to improve with grid search
    best_acc = 0 # zero initial accuracy
    # range 1 to 260 by steps of 20 for each parameter
    for depth in [1, 20, 40, 60]:
      for n_estimators in [1, 20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 220]:
            # setting up the model parameters dict
            model_parameters = {'max_depth': depth, 'random_state':0, 'n_estimators': n_estimators}
            optimized_model_rf = RandomForestClassifier(**model_parameters)
            # running cross validation for the model with the parameters
            optimized_model_rf.fit(X_train_train, t_train_train)
            val_acc = categ_accuracy(optimized_model_rf, X_train_valid, t_train_valid)
            # updating the best parameters if the avg validation accuracy is better
            if val_acc > best_acc:
                best_acc = val_acc
                best_model_parameters = model_parameters
    # display the best parameters and the associated accuracy
    print('Best RF/GB model parameters:', best_model_parameters)
    print('Best RF Classifier Accuracy:', best_acc)

    # doing grid search for gradient boosting is too computationally consuming.
    # However, we know that gradient boosting trees are essentially a boosted
    # random forest, and we can see that from the fact that their accuracy scores
    # are very similar. Therefore, we infer that optimal parameters for random
    # forest will be similar to optimal parameter for gradient boosted trees
    # and use the same optimal parameters.

    # train our model with optimal parameters from random forest grid search
    optimized_model_gb = GradientBoostingClassifier(**best_model_parameters)
    optimized_model_gb.fit(X_train_train, t_train_train)
    val_acc_gb = categ_accuracy(optimized_model_gb, X_train_valid, t_train_valid)
    # display the best accuracy
    print('Best GB Classifier Accuracy:', val_acc_gb)

    # As we can see (as listed in the report), we get better accuracy for
    # a normal random forest classifier for all types of grams, so we simply
    # use a ranadom forest for the final training and for our submission.
    # We can also see that bigrams provide the best accuracy, so we stick to
    # bigrams for our predictions submission.

    # RF is the highest model we get now, with about 0.87 so we'll train
    # a RF on the full data
    # We use random forrest for predictions. Here, we retrain a new random
    # forest model on the full training data set (so to have a better model than
    # the one we used to get accuracy) and use that for submission
    model_rf_all_opt = RandomForestClassifier(**best_model_parameters)
    model_rf_all_opt.fit(X_train, t_train)
    print("done learning")
    print()

    # get rid of training data and load test data
    del X_train
    del t_train
    del train_ids
    print("extracting test features...")
    X_test,_,t_ignore,test_ids = extract_feats(ffs, test_dir, global_feat_dict=global_feat_dict)
    print("done extracting test features")
    print()

    # make predictions on text data and write them out
    print("making predictions...")
    preds = model_rf_all_opt.predict(X_test)
    print("done making predictions")
    print()
    print("writing predictions...")
    util.write_predictions(preds, test_ids, outputfile)
    print("done!")

if __name__ == "__main__":
    main()
